"""
Data generation functions for clinical trial data
Extracted from existing monolithic app.py
"""
import pandas as pd
import numpy as np
import re
import os
from io import StringIO
from typing import Tuple, Optional, Dict, Any, List
from pathlib import Path

# Constants
NUM_COLS = ["SystolicBP", "DiastolicBP", "HeartRate", "Temperature"]
VISITS = ["Screening", "Day 1", "Week 4", "Week 12"]
ARMS = ["Active", "Placebo"]

# Import validation functions (assuming they're available in EDC service)
# For now, we'll include a simplified version here
def validate_vitals(df: pd.DataFrame) -> Dict[str, Any]:
    """Simplified validation for generation service"""
    report = {"rows": int(len(df) if df is not None else 0), "checks": []}
    if df is None or df.empty:
        report["checks"] = [
            ("columns_present", False),
            ("ranges_ok", False),
            ("fever_count_1_to_2", False),
            ("fever_hr_link_ok", False),
            ("week12_sbp_effect_approx_-5mmHg", False),
        ]
        report["week12_effect"] = None
        report["fever_count"] = 0
        return report

    required = ["SubjectID", "VisitName", "TreatmentArm", "SystolicBP",
                "DiastolicBP", "HeartRate", "Temperature"]
    report["checks"].append(("columns_present", all(c in df.columns for c in required)))

    in_range = (
        pd.to_numeric(df["SystolicBP"], errors="coerce").between(95, 200).all() and
        pd.to_numeric(df["DiastolicBP"], errors="coerce").between(55, 130).all() and
        pd.to_numeric(df["HeartRate"], errors="coerce").between(50, 120).all() and
        pd.to_numeric(df["Temperature"], errors="coerce").between(35.0, 40.0).all()
    )
    report["checks"].append(("ranges_ok", bool(in_range)))

    fevers = int((pd.to_numeric(df["Temperature"], errors="coerce") > 38.0).sum())
    report["checks"].append(("fever_count_1_to_2", 1 <= fevers <= 2))

    fever_hr_ok = True
    if fevers > 0:
        fever_rows = df.loc[pd.to_numeric(df["Temperature"], errors="coerce") > 38.0, "HeartRate"]
        fever_hr_ok = bool(pd.to_numeric(fever_rows, errors="coerce").ge(67).all())
    report["checks"].append(("fever_hr_link_ok", fever_hr_ok))

    wk12 = df[df["VisitName"] == "Week 12"].copy()
    effect_ok, effect = True, None
    if not wk12.empty:
        wk12["SystolicBP"] = pd.to_numeric(wk12["SystolicBP"], errors="coerce")
        means = wk12.groupby("TreatmentArm")["SystolicBP"].mean().to_dict()
        if "Active" in means and "Placebo" in means:
            effect = float(means["Active"] - means["Placebo"])
            effect_ok = (-7 <= effect <= -3)
    report["checks"].append(("week12_sbp_effect_approx_-5mmHg", effect_ok))
    report["week12_effect"] = effect
    report["fever_count"] = fevers
    return report


def generate_vitals_rules(n_per_arm=50, target_effect=-5.0, seed=42) -> pd.DataFrame:
    """
    Generate synthetic vitals using rules-based approach

    Args:
        n_per_arm: Number of subjects per arm
        target_effect: Target treatment effect for Week 12 SBP (Active - Placebo)
        seed: Random seed for reproducibility

    Returns:
        DataFrame with synthetic vitals data
    """
    rng = np.random.default_rng(seed)
    visits = ["Screening", "Day 1", "Week 4", "Week 12"]
    arms = (["Active"] * n_per_arm) + (["Placebo"] * n_per_arm)
    subs = [f"RA001-{i:03d}" for i in range(1, 2 * n_per_arm + 1)]

    rows = []
    for sid, arm in zip(subs, arms):
        base_val = rng.normal(130, 10)
        for v in visits:
            sbp = rng.normal(base_val, 6)
            if v == "Week 12" and arm == "Active":
                sbp += target_effect  # negative lowers Active
            dbp = rng.normal(80, 8)
            hr = int(rng.integers(60, 101))
            temp = rng.normal(36.8, 0.3)
            rows.append([
                sid, v, arm,
                int(np.clip(round(sbp), 95, 200)),
                int(np.clip(round(dbp), 55, 130)),
                int(np.clip(hr, 50, 120)),
                float(np.clip(temp, 35.0, 40.0)),
            ])

    df = pd.DataFrame(rows, columns=[
        "SubjectID", "VisitName", "TreatmentArm", "SystolicBP",
        "DiastolicBP", "HeartRate", "Temperature"
    ])

    # Add 1â€“2 fever rows w/ HR â‰¥ 67
    k = int(rng.integers(1, 3))
    idx = rng.choice(df.index, size=k, replace=False)
    df.loc[idx, "Temperature"] = rng.uniform(38.1, 38.8, size=k)
    df.loc[idx, "HeartRate"] = np.maximum(df.loc[idx, "HeartRate"], 67)

    # Snap Week-12 effect precisely
    df["SystolicBP"] = pd.to_numeric(df["SystolicBP"], errors="coerce")
    wk12 = df["VisitName"] == "Week 12"
    means = df.loc[wk12].groupby("TreatmentArm")["SystolicBP"].mean().to_dict()
    if "Active" in means and "Placebo" in means:
        current = means["Active"] - means["Placebo"]
        adjust = target_effect - current
        mask = wk12 & (df["TreatmentArm"] == "Active")
        df.loc[mask, "SystolicBP"] = (
            df.loc[mask, "SystolicBP"] + adjust
        ).round().astype(int).clip(95, 200)

    return df


def _to_num_block(df_block: pd.DataFrame) -> pd.DataFrame:
    """Convert numeric columns to float, dropping NaNs"""
    X = df_block[NUM_COLS].apply(pd.to_numeric, errors="coerce").dropna()
    return X


def fit_mvn_models(train_df: pd.DataFrame) -> Dict:
    """
    Fit mean + covariance for each (VisitName, TreatmentArm) block

    Returns:
        dict[(visit, arm)] = {"mu": np.array(4,), "cov": np.array(4x4)}
    """
    models = {}
    for v in VISITS:
        for a in ARMS:
            blk = train_df[(train_df["VisitName"] == v) & (train_df["TreatmentArm"] == a)]
            X = _to_num_block(blk)
            if len(X) >= 8:
                mu = X.mean().to_numpy()
                cov = np.cov(X.to_numpy(), rowvar=False)
            else:
                # Fallback priors
                mu = np.array([130, 80, 75, 36.8], dtype=float)
                cov = np.diag(np.array([10**2, 8**2, 8**2, 0.3**2], dtype=float))
            # Stabilize covariance
            cov = cov + 1e-6 * np.eye(len(NUM_COLS))
            models[(v, a)] = {"mu": mu, "cov": cov}
    return models


def load_pilot_vitals(use_cleaned: bool = True) -> pd.DataFrame:
    """
    Load pilot vitals data from CDISC clinical trial data.

    This data is derived from real clinical trials and provides realistic
    distributions for vital signs across different visits and treatment arms.

    Args:
        use_cleaned: If True (default), load the validated and repaired data.
                    If False, load the original unprocessed data.

    Returns:
        DataFrame with clinical trial vital signs data

    Note:
        The cleaned data has been validated and repaired to ensure:
        - All values within valid clinical ranges
        - No duplicate records
        - No missing values
        - Consistent treatment arms per subject

        To generate cleaned data, run: python data/validate_and_repair_real_data.py
    """
    # Locate the pilot data in the data directory
    # Use Path for robust path resolution (works in both local and Docker)
    current_file = Path(__file__).resolve()
    if str(current_file).startswith("/app/"):
        # Running in Docker: /app/src/generators.py -> /app
        base_path = current_file.parents[1]
    else:
        # Running locally: .../microservices/data-generation-service/src/generators.py -> project root
        base_path = current_file.parents[3]

    if use_cleaned:
        # Use validated and cleaned data (recommended)
        pilot_data_path = base_path / "data" / "pilot_trial_cleaned.csv"

        if not pilot_data_path.exists():
            # Fall back to original if cleaned doesn't exist
            print("âš ï¸  Warning: Cleaned data not found. Using original data.")
            print("   Run 'python data/validate_and_repair_real_data.py' to generate cleaned data.")
            pilot_data_path = base_path / "data" / "pilot_trial.csv"
    else:
        # Use original unprocessed data
        pilot_data_path = base_path / "data" / "pilot_trial.csv"

    if not pilot_data_path.exists():
        raise FileNotFoundError(
            f"Pilot data not found at: {pilot_data_path}. "
            "Run 'python data/process_cdisc_data.py' to generate the pilot data from CDISC sources."
        )

    df = pd.read_csv(pilot_data_path)

    # Validate expected columns
    required_cols = ["SubjectID", "VisitName", "TreatmentArm",
                     "SystolicBP", "DiastolicBP", "HeartRate", "Temperature"]
    missing = [c for c in required_cols if c not in df.columns]
    if missing:
        raise ValueError(f"Pilot data missing required columns: {missing}")

    return df


def generate_vitals_mvn(n_per_arm=50, target_effect=-5.0, seed=123,
                        train_source: str = "pilot",
                        current_df: Optional[pd.DataFrame] = None) -> pd.DataFrame:
    """
    Generate vitals using Multivariate Normal learned from training data

    Args:
        n_per_arm: Number of subjects per arm
        target_effect: Target treatment effect
        seed: Random seed
        train_source: 'pilot' or 'current'
        current_df: Current dataframe if train_source='current'

    Returns:
        DataFrame with synthetic vitals
    """
    rng = np.random.default_rng(seed)

    if train_source == "current" and isinstance(current_df, pd.DataFrame) and not current_df.empty:
        train_df = current_df.copy()
    else:
        train_df = load_pilot_vitals()

    models = fit_mvn_models(train_df)

    rows = []
    subj_active = [f"RA001-{i:03d}" for i in range(1, n_per_arm + 1)]
    subj_placebo = [f"RA001-{i:03d}" for i in range(n_per_arm + 1, 2 * n_per_arm + 1)]

    for arm, subjects in [("Active", subj_active), ("Placebo", subj_placebo)]:
        for sid in subjects:
            for visit in VISITS:
                m = models[(visit, arm)]
                x = np.random.default_rng(rng.integers(0, 2**31 - 1)).multivariate_normal(
                    mean=m["mu"], cov=m["cov"], size=1
                )[0]
                sbp, dbp, hr, temp = x.tolist()
                rows.append([
                    sid, visit, arm,
                    int(np.clip(round(sbp), 95, 200)),
                    int(np.clip(round(dbp), 55, 130)),
                    int(np.clip(round(hr), 50, 120)),
                    float(np.clip(temp, 35.0, 40.0)),
                ])

    df = pd.DataFrame(rows, columns=["SubjectID", "VisitName", "TreatmentArm"] + NUM_COLS)

    # Add 1â€“2 fever rows with HR >= 67
    k = int(rng.integers(1, 3))
    idx = rng.choice(df.index, size=k, replace=False)
    df.loc[idx, "Temperature"] = rng.uniform(38.1, 38.8, size=k)
    df.loc[idx, "HeartRate"] = np.maximum(df.loc[idx, "HeartRate"], 67)

    # Snap Week-12 effect exactly to target
    wk12 = df["VisitName"] == "Week 12"
    means = df.loc[wk12].groupby("TreatmentArm")["SystolicBP"].mean().to_dict()
    if "Active" in means and "Placebo" in means:
        current = means["Active"] - means["Placebo"]
        adjust = target_effect - current
        mask = wk12 & (df["TreatmentArm"] == "Active")
        df.loc[mask, "SystolicBP"] = (
            df.loc[mask, "SystolicBP"] + adjust
        ).round().astype(int).clip(95, 200)

    return df


# ======================== LLM Generation ========================
def _openai_chat(prompt: str, api_key: str, model: str = "gpt-4o-mini") -> str:
    """Call OpenAI API"""
    try:
        from openai import OpenAI
    except Exception as e:
        raise RuntimeError("OpenAI SDK not installed. `pip install openai`") from e

    if not api_key:
        raise RuntimeError("Missing OpenAI API key.")

    client = OpenAI(api_key=api_key)
    resp = client.chat.completions.create(
        model=model,
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2,
    )
    return resp.choices[0].message.content


def call_llm(prompt: str, provider: str = "openai",
             api_key: Optional[str] = None, model: str = "gpt-4o-mini") -> str:
    """Call LLM provider"""
    if provider == "openai":
        return _openai_chat(prompt, api_key=api_key or os.environ.get("OPENAI_API_KEY"), model=model)
    raise RuntimeError(f"LLM provider '{provider}' not supported.")


LLM_SYSTEM_PREFIX = """You are a meticulous biostatistician. You MUST obey the following output rules:
1) Output ONLY a single CSV code block (markdown fenced), nothing else.
2) Include EXACT headers: SubjectID,VisitName,TreatmentArm,SystolicBP,DiastolicBP,HeartRate,Temperature
3) Do NOT add commentary, units in cells, or extra columns.
"""

DEFAULT_CSV_PROMPT_TEMPLATE = """Generate a VITALS CSV for a Phase 3 {indication} trial.
Arms: Active vs Placebo. Subjects per arm: {n_per_arm}.
Visits: Screening, Day 1, Week 4, Week 12.

Constraints:
- SystolicBP ~ N(130,10), clamp [95,200], integers
- DiastolicBP ~ N(80,8), clamp [55,130], integers
- HeartRate in [60,100], integers
- Temperature ~ N(36.8,0.3); include 1â€“2 rows with Temp > 38.0Â°C; for those rows, HeartRate >= 67
- Week 12 treatment effect: mean(SBP, Active) - mean(SBP, Placebo) â‰ˆ {target_effect} mmHg (acceptable range -7..-3 if target is -5)
"""


def build_llm_prompt(indication: str, n_per_arm: int, target_effect: float,
                     prompt_template: Optional[str] = None,
                     extra_instructions: str = "") -> str:
    """Build LLM prompt for data generation"""
    tpl = prompt_template or DEFAULT_CSV_PROMPT_TEMPLATE
    body = tpl.format(indication=indication, n_per_arm=n_per_arm, target_effect=target_effect)
    if extra_instructions:
        body += "\n\nAdditional instructions (must still obey schema & CSV-only):\n" + extra_instructions.strip()
    body += "\n\nOutput: ONLY a single CSV code block with headers and no prose."
    return LLM_SYSTEM_PREFIX + "\n\n" + body


def extract_csv_block(text: str) -> str:
    """Extract CSV from markdown code block"""
    m = re.search(r"```(?:csv)?\s*(.*?)```", text, re.S | re.I)
    return m.group(1).strip() if m else text.strip()


def generate_vitals_llm(indication: str, n_per_arm: int, target_effect: float,
                        api_key: Optional[str] = None, model: str = "gpt-4o-mini",
                        prompt_template: Optional[str] = None,
                        extra_instructions: str = "") -> Tuple[pd.DataFrame, str]:
    """Generate vitals using LLM"""
    prompt = build_llm_prompt(indication, n_per_arm, target_effect,
                              prompt_template, extra_instructions)
    content = call_llm(prompt, api_key=api_key, model=model)
    csv_text = extract_csv_block(content)
    df = pd.read_csv(StringIO(csv_text))
    return df, prompt


def generate_vitals_llm_with_repair(indication: str, n_per_arm: int, target_effect: float,
                                     api_key: Optional[str] = None, model: str = "gpt-4o-mini",
                                     prompt_template: Optional[str] = None,
                                     extra_instructions: str = "",
                                     max_iters: int = 2) -> Tuple[pd.DataFrame, Dict, str]:
    """
    Generate vitals using LLM with automatic repair loop

    Returns:
        (dataframe, validation_report, prompt_used)
    """
    df, used_prompt = generate_vitals_llm(indication, n_per_arm, target_effect,
                                          api_key, model, prompt_template, extra_instructions)
    rep = validate_vitals(df)

    for _ in range(max_iters):
        if all(bool(v) for _, v in rep["checks"]):
            break
        fail_notes = [name for name, ok in rep["checks"] if not bool(ok)]
        fb = f"\nRegenerate. The following checks failed: {fail_notes}. Keep schema EXACT. Keep N per arm {n_per_arm}. Target effect {target_effect}."
        content = call_llm(used_prompt + fb, api_key=api_key, model=model)
        df = pd.read_csv(StringIO(extract_csv_block(content)))
        rep = validate_vitals(df)

    return df, rep, used_prompt


def generate_oncology_ae(n_subjects=30, seed=7) -> pd.DataFrame:
    """
    Generate synthetic oncology adverse events

    Returns:
        DataFrame with SDTM AE domain structure
    """
    rng = np.random.default_rng(seed)
    subjects = [f"ONC{idx:03d}" for idx in range(1, n_subjects + 1)]
    terms = [
        ("Neutropenia", "Blood and lymphatic system disorders"),
        ("Nausea", "Gastrointestinal disorders"),
        ("Anemia", "Blood and lymphatic system disorders"),
        ("Fatigue", "General disorders and administration site conditions"),
        ("Elevated ALT", "Hepatobiliary disorders"),
    ]
    rows = []

    # Guarantee 2 serious+related and 1 fatal
    rows.append([rng.choice(subjects), "Myelosuppression",
                 "Blood and lymphatic system disorders", "Y", "Y", "ONGOING"])
    rows.append([rng.choice(subjects), "Hepatic failure",
                 "Hepatobiliary disorders", "Y", "Y", "FATAL"])

    for _ in range(max(20, n_subjects)):
        subj = rng.choice(subjects)
        term, bod = terms[rng.integers(0, len(terms))]
        ser = "Y" if term in ("Neutropenia", "Anemia") and rng.random() < 0.2 else "N"
        rel = "Y" if rng.random() < 0.6 else "N"
        out = "RESOLVED" if rng.random() < 0.8 else "ONGOING"
        rows.append([subj, term, bod, ser, rel, out])

    return pd.DataFrame(rows, columns=["USUBJID", "AETERM", "AEBODSYS", "AESER", "AEREL", "AEOUT"])


def generate_vitals_bootstrap(
    training_df: pd.DataFrame,
    n_per_arm: int = 50,
    target_effect: float = -5.0,
    jitter_frac: float = 0.05,
    cat_flip_prob: float = 0.05,
    seed: int = 42,
    subject_ids: Optional[List[str]] = None,
    visit_schedule: Optional[List[str]] = None,
    treatment_arms: Optional[Dict[str, str]] = None
) -> pd.DataFrame:
    """
    Bootstrap-based synthetic data generation with clinical trial enhancements

    Uses row sampling with intelligent augmentation, fine-tuned for clinical trials:
    - Bootstrap sampling with replacement
    - Gaussian jitter on vitals (scaled by column std)
    - Respects clinical constraints (BP, HR, Temp ranges)
    - Maintains integer types for appropriate fields
    - Generates proper SubjectIDs (RA###-###)
    - Ensures complete visit sequences per subject
    - Applies treatment effect at Week 12

    Best for: Quick augmentation from pilot study data or existing datasets

    Args:
        training_df: Training data (pilot study or existing dataset)
                    Must contain: SubjectID, VisitName, TreatmentArm, SystolicBP,
                                  DiastolicBP, HeartRate, Temperature
        n_per_arm: Number of subjects per treatment arm
        target_effect: Target SystolicBP reduction (Active - Placebo) at Week 12
        jitter_frac: Fraction of std for numeric noise (0.05 = 5% of std)
        cat_flip_prob: Probability of flipping categorical values for diversity
        seed: Random seed for reproducibility

    Returns:
        DataFrame with synthetic vitals data
    """
    from pandas.api.types import is_integer_dtype

    rng = np.random.default_rng(seed)
    np.random.seed(seed)

    # Validate input
    required_cols = ["SubjectID", "VisitName", "TreatmentArm", "SystolicBP",
                     "DiastolicBP", "HeartRate", "Temperature"]
    missing = [c for c in required_cols if c not in training_df.columns]
    if missing:
        raise ValueError(f"Training data missing required columns: {missing}")

    # Calculate target total rows (subjects Ã— visits Ã— arms)
    target_n = n_per_arm * len(VISITS) * len(ARMS)
    n0 = len(training_df)

    if n0 == 0:
        raise ValueError("Training data is empty")

    # Sample complete rows with replacement
    needed = max(target_n - n0, 0)
    if needed > 0:
        syn = training_df.sample(n=needed, replace=True, random_state=seed).reset_index(drop=True)
    else:
        syn = training_df.sample(n=target_n, replace=False, random_state=seed).reset_index(drop=True)

    # ===== Numeric Jitter with Clinical Constraints =====
    num_cols = ["SystolicBP", "DiastolicBP", "HeartRate", "Temperature"]
    constraints = {
        "SystolicBP": (95, 200),
        "DiastolicBP": (55, 130),
        "HeartRate": (50, 120),
        "Temperature": (35.0, 40.0)
    }

    for col in num_cols:
        s = syn[col].copy()
        base = pd.to_numeric(training_df[col], errors="coerce")
        std = base.std()

        if pd.isna(std) or std == 0:
            continue

        # Add Gaussian noise scaled by std
        scale = max(std * jitter_frac, 1e-12)
        noise = rng.normal(0.0, scale, size=len(s))
        s_noisy = pd.to_numeric(s, errors="coerce") + noise

        # Clip to clinical constraints
        col_min, col_max = constraints[col]
        s_noisy = np.clip(s_noisy, col_min, col_max)

        # Integer columns (BP, HR)
        if col in ["SystolicBP", "DiastolicBP", "HeartRate"]:
            s_noisy = np.round(s_noisy).astype(np.int64)
        else:
            s_noisy = s_noisy.astype(float)

        syn[col] = s_noisy

    # ===== Ensure SystolicBP > DiastolicBP by at least 5 mmHg =====
    mask = syn["SystolicBP"] <= syn["DiastolicBP"] + 5
    if mask.any():
        syn.loc[mask, "SystolicBP"] = syn.loc[mask, "DiastolicBP"] + rng.integers(5, 20, size=mask.sum())
        # Re-clip to max
        syn.loc[mask, "SystolicBP"] = np.clip(syn.loc[mask, "SystolicBP"], 95, 200)

    # ===== Categorical Flip (VisitName and TreatmentArm - low probability) =====
    if cat_flip_prob > 0:
        # Flip VisitName occasionally for diversity
        mask = rng.random(len(syn)) < cat_flip_prob
        if mask.any():
            syn.loc[mask, "VisitName"] = rng.choice(VISITS, size=mask.sum())

        # Flip TreatmentArm occasionally
        mask = rng.random(len(syn)) < cat_flip_prob
        if mask.any():
            syn.loc[mask, "TreatmentArm"] = rng.choice(ARMS, size=mask.sum())

    # ===== Combine original + synthetic =====
    out = pd.concat([training_df, syn], ignore_index=True)

    # ===== Ensure complete visit sequences per subject =====
    # Group by subject and ensure all 4 visits present
    subjects_visits = out.groupby("SubjectID")["VisitName"].apply(set)
    incomplete_subjects = subjects_visits[subjects_visits.apply(lambda x: len(x) < len(VISITS))].index

    # Fill missing visits by duplicating existing rows
    rows_to_add = []
    for subj in incomplete_subjects:
        subj_data = out[out["SubjectID"] == subj]
        missing_visits = set(VISITS) - set(subj_data["VisitName"])

        for visit in missing_visits:
            # Use a random existing row from this subject as template
            template = subj_data.sample(n=1, random_state=seed).iloc[0].copy()
            template["VisitName"] = visit
            rows_to_add.append(template)

    if rows_to_add:
        out = pd.concat([out, pd.DataFrame(rows_to_add)], ignore_index=True)

    # ===== Regenerate SubjectIDs using coordination parameters (if provided) =====
    if subject_ids is not None and treatment_arms is not None:
        # Use coordinated subject IDs and treatment arms
        unique_subjects = out["SubjectID"].unique()
        subject_mapping = {}

        # Map old subjects to coordinated subject IDs
        for i, old_subj in enumerate(unique_subjects):
            if i < len(subject_ids):
                new_id = subject_ids[i]
                subject_mapping[old_subj] = new_id
                # Also update treatment arm to match coordination
                out.loc[out["SubjectID"] == old_subj, "TreatmentArm"] = treatment_arms[new_id]

        out["SubjectID"] = out["SubjectID"].map(subject_mapping)
    else:
        # Generate default subject IDs
        unique_subjects = out["SubjectID"].unique()
        subject_mapping = {}
        counter = 1

        for old_subj in unique_subjects:
            subject_mapping[old_subj] = f"RA001-{counter:03d}"
            counter += 1

        out["SubjectID"] = out["SubjectID"].map(subject_mapping)

    # ===== Apply Treatment Effect at Week 12 =====
    week12 = out["VisitName"] == "Week 12"
    active = out["TreatmentArm"] == "Active"
    placebo = out["TreatmentArm"] == "Placebo"

    # Calculate current effect
    active_week12_mean = out[week12 & active]["SystolicBP"].mean()
    placebo_week12_mean = out[week12 & placebo]["SystolicBP"].mean()
    current_effect = active_week12_mean - placebo_week12_mean

    # Adjust to target effect
    adjustment = target_effect - current_effect

    # Apply adjustment to Active arm at Week 12
    mask = week12 & active
    out.loc[mask, "SystolicBP"] = out.loc[mask, "SystolicBP"] + adjustment

    # Re-clip after adjustment
    out.loc[mask, "SystolicBP"] = np.clip(out.loc[mask, "SystolicBP"], 95, 200).astype(int)

    # ===== Sample to exact target size =====
    # Group by treatment arm and ensure balanced
    active_df = out[out["TreatmentArm"] == "Active"]
    placebo_df = out[out["TreatmentArm"] == "Placebo"]

    # Get unique subjects per arm
    active_subjects = active_df["SubjectID"].unique()
    placebo_subjects = placebo_df["SubjectID"].unique()

    # Sample subjects
    if len(active_subjects) > n_per_arm:
        active_subjects = rng.choice(active_subjects, size=n_per_arm, replace=False)
    if len(placebo_subjects) > n_per_arm:
        placebo_subjects = rng.choice(placebo_subjects, size=n_per_arm, replace=False)

    # Filter to selected subjects
    out = out[
        out["SubjectID"].isin(active_subjects) | out["SubjectID"].isin(placebo_subjects)
    ].reset_index(drop=True)

    # ===== Add 1-2 fever rows (Temperature > 38Â°C) =====
    fever_mask = out["Temperature"] > 38.0
    current_fever_count = fever_mask.sum()

    if current_fever_count < 1:
        # Add 1 fever
        idx = rng.choice(out.index, size=1)
        out.loc[idx, "Temperature"] = rng.uniform(38.1, 39.5, size=1)
    elif current_fever_count > 2:
        # Remove excess fevers
        fever_indices = out[fever_mask].index
        to_fix = rng.choice(fever_indices, size=current_fever_count - 2, replace=False)
        out.loc[to_fix, "Temperature"] = rng.uniform(36.5, 37.8, size=len(to_fix))

    # Ensure fever rows have HR >= 67
    fever_mask = out["Temperature"] > 38.0
    low_hr = out["HeartRate"] < 67
    to_fix = fever_mask & low_hr
    if to_fix.any():
        out.loc[to_fix, "HeartRate"] = rng.integers(67, 100, size=to_fix.sum())

    # Sort by SubjectID and VisitName for clean output
    visit_order = {v: i for i, v in enumerate(VISITS)}
    out["_visit_order"] = out["VisitName"].map(visit_order)
    out = out.sort_values(["SubjectID", "_visit_order"]).drop(columns=["_visit_order"])

    return out.reset_index(drop=True)


def generate_demographics(n_subjects=100, seed=42) -> pd.DataFrame:
    """
    Generate realistic demographics data

    Args:
        n_subjects: Number of subjects
        seed: Random seed for reproducibility

    Returns:
        DataFrame with demographic data including age, gender, race, ethnicity,
        physical measurements (height, weight, BMI), and smoking status
    """
    np.random.seed(seed)
    rng = np.random.default_rng(seed)

    demographics = []

    for i in range(n_subjects):
        subject_id = f"RA001-{i+1:03d}"

        # Age: Normal distribution around 55, range 18-85
        age = int(np.clip(rng.normal(55, 12), 18, 85))

        # Gender: 50/50 split
        gender = rng.choice(["Male", "Female"])

        # Race: US demographics approximate
        race = rng.choice(
            ["White", "Black", "Asian", "Other"],
            p=[0.60, 0.13, 0.06, 0.21]
        )

        # Ethnicity: ~18% Hispanic
        ethnicity = rng.choice(
            ["Hispanic or Latino", "Not Hispanic or Latino"],
            p=[0.18, 0.82]
        )

        # Height: gender-specific (in cm)
        if gender == "Male":
            height_cm = rng.normal(175, 7)  # ~5'9"
        else:
            height_cm = rng.normal(162, 6.5)  # ~5'4"
        height_cm = np.clip(height_cm, 140, 220)

        # Weight: correlated with age (older = slightly heavier)
        base_weight = 75 if gender == "Male" else 65
        weight_kg = base_weight + rng.normal(0, 12) + (age - 55) * 0.2
        weight_kg = np.clip(weight_kg, 40, 200)

        # BMI
        bmi = weight_kg / ((height_cm / 100) ** 2)

        # Smoking: age-correlated (older = more former smokers)
        if age < 40:
            smoking_status = rng.choice(
                ["Never", "Current", "Former"],
                p=[0.70, 0.25, 0.05]
            )
        else:
            smoking_status = rng.choice(
                ["Never", "Current", "Former"],
                p=[0.50, 0.15, 0.35]
            )

        demographics.append({
            "SubjectID": subject_id,
            "Age": age,
            "Gender": gender,
            "Race": race,
            "Ethnicity": ethnicity,
            "Height_cm": round(height_cm, 1),
            "Weight_kg": round(weight_kg, 1),
            "BMI": round(bmi, 1),
            "SmokingStatus": smoking_status
        })

    return pd.DataFrame(demographics)


def generate_labs(n_subjects=100, seed=42) -> pd.DataFrame:
    """
    Generate realistic lab results data

    Args:
        n_subjects: Number of subjects
        seed: Random seed for reproducibility

    Returns:
        DataFrame with lab results including hematology, chemistry, and lipids
        for multiple visits per subject
    """
    np.random.seed(seed)
    rng = np.random.default_rng(seed)

    visits = ["Screening", "Week 4", "Week 12"]
    labs = []

    for i in range(n_subjects):
        subject_id = f"RA001-{i+1:03d}"

        for visit in visits:
            # Hematology (Complete Blood Count)
            hemoglobin = rng.normal(14.5, 1.5)  # 12-18 g/dL
            hemoglobin = np.clip(hemoglobin, 12, 18)

            hematocrit = hemoglobin * 3  # Hct â‰ˆ 3Ã— Hgb
            hematocrit = np.clip(hematocrit, 36, 50)

            wbc = rng.normal(7.5, 1.5)  # 4-11 K/Î¼L
            wbc = np.clip(wbc, 4, 11)

            platelets = rng.normal(250, 50)  # 150-400 K/Î¼L
            platelets = np.clip(platelets, 150, 400)

            # Chemistry (Metabolic Panel)
            glucose = rng.normal(90, 10)  # 70-100 mg/dL
            glucose = np.clip(glucose, 70, 120)

            creatinine = rng.normal(1.0, 0.15)  # 0.7-1.3 mg/dL
            creatinine = np.clip(creatinine, 0.7, 1.3)

            bun = rng.normal(15, 3)  # 7-20 mg/dL
            bun = np.clip(bun, 7, 20)

            alt = rng.normal(30, 10)  # 7-56 U/L
            alt = np.clip(alt, 7, 56)

            ast = rng.normal(25, 8)  # 10-40 U/L
            ast = np.clip(ast, 10, 40)

            bilirubin = rng.normal(0.7, 0.2)  # 0.3-1.2 mg/dL
            bilirubin = np.clip(bilirubin, 0.3, 1.2)

            # Lipids
            total_chol = rng.normal(190, 30)
            total_chol = np.clip(total_chol, 120, 300)

            ldl = rng.normal(110, 25)
            ldl = np.clip(ldl, 50, 200)

            hdl = rng.normal(50, 10)
            hdl = np.clip(hdl, 30, 80)

            triglycerides = rng.normal(130, 40)
            triglycerides = np.clip(triglycerides, 50, 250)

            labs.append({
                "SubjectID": subject_id,
                "VisitName": visit,
                "TestDate": "2025-01-15",  # Would be calculated in production
                "Hemoglobin": round(hemoglobin, 1),
                "Hematocrit": round(hematocrit, 1),
                "WBC": round(wbc, 2),
                "Platelets": round(platelets, 1),
                "Glucose": round(glucose, 1),
                "Creatinine": round(creatinine, 2),
                "BUN": round(bun, 1),
                "ALT": round(alt, 1),
                "AST": round(ast, 1),
                "Bilirubin": round(bilirubin, 2),
                "TotalCholesterol": round(total_chol, 1),
                "LDL": round(ldl, 1),
                "HDL": round(hdl, 1),
                "Triglycerides": round(triglycerides, 1)
            })

    return pd.DataFrame(labs)


# ======================== AACT-Enhanced Generators (v4.0) ========================
"""
AACT v4.0 Enhanced Generators - Using maximum real-world data

These generators use comprehensive AACT statistics from 557K+ trials:
- Real baseline vitals by indication/phase
- Real study durations for visit schedules
- Real demographics (age, gender distributions)
- Real treatment arm configurations
- Real baseline characteristics for stratification

All functions gracefully fall back to defaults if AACT data unavailable.
"""

try:
    from aact_utils import (
        get_baseline_vitals,
        get_demographics,
        get_treatment_arms,
        get_baseline_characteristics,
        get_dropout_patterns,
        get_adverse_events
    )
    AACT_AVAILABLE = True
except ImportError:
    AACT_AVAILABLE = False
    print("âš ï¸  AACT utilities not available. Enhanced generators will use fallback defaults.")


def generate_visit_schedule(duration_months: int, n_visits: int = 4) -> Tuple[List[str], List[int]]:
    """
    Generate realistic visit schedule based on actual study duration

    Args:
        duration_months: Total study duration in months (from AACT actual_duration)
        n_visits: Number of visits (default: 4)

    Returns:
        Tuple of (visit_names, visit_days_from_baseline)

    Examples:
        >>> generate_visit_schedule(12, 4)
        (['Screening', 'Day 1', 'Month 4', 'Month 12'], [0, 1, 120, 365])

        >>> generate_visit_schedule(24, 5)
        (['Screening', 'Day 1', 'Month 6', 'Month 12', 'Month 24'], [0, 1, 180, 365, 730])
    """
    visit_names = ["Screening", "Day 1"]
    visit_days = [0, 1]

    if n_visits <= 2:
        return visit_names, visit_days

    # Distribute remaining visits evenly across study duration
    remaining_visits = n_visits - 2
    total_days = duration_months * 30  # Approximate

    for i in range(1, remaining_visits + 1):
        # Space visits evenly
        months_from_baseline = int((i / remaining_visits) * duration_months)

        if months_from_baseline <= 1:
            visit_name = "Week 2"
            days = 14
        elif months_from_baseline <= 3:
            visit_name = f"Week {months_from_baseline * 4}"
            days = months_from_baseline * 30
        else:
            visit_name = f"Month {months_from_baseline}"
            days = months_from_baseline * 30

        visit_names.append(visit_name)
        visit_days.append(days)

    return visit_names, visit_days


def generate_vitals_mvn_aact(
    indication: str = "hypertension",
    phase: str = "Phase 3",
    n_per_arm: int = 50,
    target_effect: float = -5.0,
    seed: int = 123,
    use_duration: bool = True,
    subject_ids: Optional[List[str]] = None,
    visit_schedule: Optional[List[str]] = None,
    treatment_arms: Optional[Dict[str, str]] = None
) -> pd.DataFrame:
    """
    Generate vitals using MVN with AACT real-world data (v4.0)

    Enhancements over base MVN generator:
    - Uses real baseline vitals by indication/phase from AACT
    - Uses real study duration for visit schedule
    - Maintains all original MVN quality (covariance structure, etc.)
    - **NEW**: Supports coordination with other datasets via subject_ids, visit_schedule, treatment_arms

    Args:
        indication: Disease indication (e.g., 'hypertension', 'diabetes')
        phase: Trial phase (e.g., 'Phase 3')
        n_per_arm: Number of subjects per arm
        target_effect: Target SBP reduction (Active - Placebo) at final visit
        seed: Random seed
        use_duration: If True, use AACT duration for visit schedule
        subject_ids: Optional list of subject IDs (for coordination with other datasets)
        visit_schedule: Optional list of visit names (for coordination with other datasets)
        treatment_arms: Optional dict mapping subject_id -> "Active" or "Placebo" (for coordination)

    Returns:
        DataFrame with synthetic vitals using AACT baseline statistics
    """
    rng = np.random.default_rng(seed)

    # Get AACT data
    if AACT_AVAILABLE:
        baseline_vitals = get_baseline_vitals(indication, phase)
        demographics = get_demographics(indication, phase)

        # Extract baseline statistics
        sbp_mean = baseline_vitals.get('systolic', {}).get('mean', 140.0)
        sbp_std = baseline_vitals.get('systolic', {}).get('std', 15.0)
        dbp_mean = baseline_vitals.get('diastolic', {}).get('mean', 85.0)
        dbp_std = baseline_vitals.get('diastolic', {}).get('std', 10.0)
        hr_mean = baseline_vitals.get('heart_rate', {}).get('mean', 72.0)
        hr_std = baseline_vitals.get('heart_rate', {}).get('std', 10.0)
        temp_mean = baseline_vitals.get('temperature', {}).get('mean', 36.7) if 'temperature' in baseline_vitals else 36.7
        temp_std = baseline_vitals.get('temperature', {}).get('std', 0.3) if 'temperature' in baseline_vitals else 0.3

        # Get realistic study duration
        if use_duration and 'actual_duration' in demographics:
            duration_months = int(demographics['actual_duration'].get('median_months', 12))
        else:
            duration_months = 12  # Default
    else:
        # Fallback defaults
        sbp_mean, sbp_std = 140.0, 15.0
        dbp_mean, dbp_std = 85.0, 10.0
        hr_mean, hr_std = 72.0, 10.0
        temp_mean, temp_std = 36.7, 0.3
        duration_months = 12

    # ============================================================================
    # Use Coordination Parameters if provided (for comprehensive study generation)
    # ============================================================================

    # Use provided visit schedule or generate from AACT/defaults
    if visit_schedule is not None:
        visit_names = visit_schedule
    elif use_duration:
        visit_names, visit_days = generate_visit_schedule(duration_months, n_visits=4)
    else:
        visit_names = VISITS

    # Use provided subject IDs or generate defaults
    if subject_ids is not None:
        # Use provided subject IDs (already includes both arms)
        all_subjects = subject_ids
    else:
        # Generate default subject IDs
        subj_active = [f"RA001-{i:03d}" for i in range(1, n_per_arm + 1)]
        subj_placebo = [f"RA001-{i:03d}" for i in range(n_per_arm + 1, 2 * n_per_arm + 1)]
        all_subjects = subj_active + subj_placebo

    # Use provided treatment arms or generate defaults
    if treatment_arms is None:
        # Generate default treatment assignments
        treatment_arms = {}
        for i, subj in enumerate(all_subjects):
            treatment_arms[subj] = "Active" if i < n_per_arm else "Placebo"

    # Build MVN models using AACT baseline statistics
    models = {}
    for visit in visit_names:
        for arm in ARMS:
            # Use AACT mean as baseline
            mu = np.array([sbp_mean, dbp_mean, hr_mean, temp_mean], dtype=float)

            # Build covariance matrix (preserve correlations)
            cov = np.diag([sbp_std**2, dbp_std**2, hr_std**2, temp_std**2])

            # Add small correlations (SBP-DBP typically correlated)
            cov[0, 1] = cov[1, 0] = 0.6 * sbp_std * dbp_std  # SBP-DBP correlation
            cov[1, 2] = cov[2, 1] = 0.3 * dbp_std * hr_std   # DBP-HR correlation

            # Stabilize
            cov = cov + 1e-6 * np.eye(len(NUM_COLS))

            models[(visit, arm)] = {"mu": mu, "cov": cov}

    # Generate vitals data using coordinated subject IDs and treatment arms
    rows = []
    for sid in all_subjects:
        arm = treatment_arms[sid]  # Use coordinated treatment assignment
        for visit in visit_names:
            m = models[(visit, arm)]
            x = rng.multivariate_normal(mean=m["mu"], cov=m["cov"], size=1)[0]
            sbp, dbp, hr, temp = x.tolist()

            rows.append([
                sid, visit, arm,
                int(np.clip(round(sbp), 95, 200)),
                int(np.clip(round(dbp), 55, 130)),
                int(np.clip(round(hr), 50, 120)),
                float(np.clip(temp, 35.0, 40.0)),
            ])

    df = pd.DataFrame(rows, columns=["SubjectID", "VisitName", "TreatmentArm"] + NUM_COLS)

    # Add 1-2 fever rows
    k = int(rng.integers(1, 3))
    idx = rng.choice(df.index, size=k, replace=False)
    df.loc[idx, "Temperature"] = rng.uniform(38.1, 38.8, size=k)
    df.loc[idx, "HeartRate"] = np.maximum(df.loc[idx, "HeartRate"], 67)

    # Snap Week-12 (or final visit) effect to target
    final_visit = visit_names[-1]
    wk12 = df["VisitName"] == final_visit
    means = df.loc[wk12].groupby("TreatmentArm")["SystolicBP"].mean().to_dict()

    if "Active" in means and "Placebo" in means:
        current = means["Active"] - means["Placebo"]
        adjust = target_effect - current
        mask = wk12 & (df["TreatmentArm"] == "Active")
        df.loc[mask, "SystolicBP"] = (
            df.loc[mask, "SystolicBP"] + adjust
        ).round().astype(int).clip(95, 200)

    return df


def generate_vitals_bootstrap_aact(
    indication: str = "hypertension",
    phase: str = "Phase 3",
    n_per_arm: int = 50,
    target_effect: float = -5.0,
    jitter_frac: float = 0.05,
    seed: int = 42,
    use_duration: bool = True,
    subject_ids: Optional[List[str]] = None,
    visit_schedule: Optional[List[str]] = None,
    treatment_arms: Optional[Dict[str, str]] = None
) -> pd.DataFrame:
    """
    Generate vitals using Bootstrap with AACT real-world data (v4.0)

    Enhancements over base Bootstrap generator:
    - Uses pilot data enriched with AACT baseline patterns
    - Uses real study duration for visit schedule
    - Maintains all original Bootstrap quality

    Args:
        indication: Disease indication
        phase: Trial phase
        n_per_arm: Subjects per arm
        target_effect: Target SBP reduction
        jitter_frac: Jitter fraction (default: 0.05)
        seed: Random seed
        use_duration: Use AACT duration for visits

    Returns:
        DataFrame with synthetic vitals
    """
    # Load pilot data
    pilot_df = load_pilot_vitals(use_cleaned=True)

    # Get AACT data for visit schedule
    if AACT_AVAILABLE and use_duration:
        demographics = get_demographics(indication, phase)
        if 'actual_duration' in demographics:
            duration_months = int(demographics['actual_duration'].get('median_months', 12))
            visit_names, _ = generate_visit_schedule(duration_months, n_visits=4)

            # Map pilot visits to new visit names
            visit_mapping = {old: new for old, new in zip(VISITS, visit_names)}
            pilot_df["VisitName"] = pilot_df["VisitName"].map(visit_mapping).fillna(pilot_df["VisitName"])

    # Use provided visit schedule or get from AACT
    if visit_schedule is None and AACT_AVAILABLE and use_duration:
        demographics = get_demographics(indication, phase)
        if 'actual_duration' in demographics:
            duration_months = int(demographics['actual_duration'].get('median_months', 12))
            visit_names, _ = generate_visit_schedule(duration_months, n_visits=4)
            visit_schedule = visit_names

    # Use standard bootstrap generator with modified pilot data and coordination parameters
    result = generate_vitals_bootstrap(
        training_df=pilot_df,
        n_per_arm=n_per_arm,
        target_effect=target_effect,
        jitter_frac=jitter_frac,
        seed=seed,
        subject_ids=subject_ids,          # ðŸ”‘ Pass coordination
        visit_schedule=visit_schedule,     # ðŸ”‘ Pass coordination
        treatment_arms=treatment_arms      # ðŸ”‘ Pass coordination
    )

    return result


def generate_vitals_rules_aact(
    indication: str = "hypertension",
    phase: str = "Phase 3",
    n_per_arm: int = 50,
    target_effect: float = -5.0,
    seed: int = 42,
    use_duration: bool = True,
    subject_ids: Optional[List[str]] = None,
    visit_schedule: Optional[List[str]] = None,
    treatment_arms: Optional[Dict[str, str]] = None
) -> pd.DataFrame:
    """
    Generate vitals using Rules with AACT real-world data (v4.0)

    Enhancements over base Rules generator:
    - Uses real baseline vitals by indication/phase
    - Uses real study duration for visit schedule
    - Maintains deterministic rules-based approach
    - **NEW**: Supports coordination with other datasets

    Args:
        indication: Disease indication
        phase: Trial phase
        n_per_arm: Subjects per arm
        target_effect: Target SBP reduction
        seed: Random seed
        use_duration: Use AACT duration for visits
        subject_ids: Optional list of subject IDs (for coordination)
        visit_schedule: Optional list of visit names (for coordination)
        treatment_arms: Optional dict mapping subject_id -> treatment arm (for coordination)

    Returns:
        DataFrame with synthetic vitals
    """
    rng = np.random.default_rng(seed)

    # Get AACT baseline statistics
    if AACT_AVAILABLE:
        baseline_vitals = get_baseline_vitals(indication, phase)
        demographics = get_demographics(indication, phase)

        base_sbp = baseline_vitals.get('systolic', {}).get('mean', 130.0)
        sbp_std = baseline_vitals.get('systolic', {}).get('std', 10.0)
        base_dbp = baseline_vitals.get('diastolic', {}).get('mean', 80.0)
        dbp_std = baseline_vitals.get('diastolic', {}).get('std', 8.0)

        if visit_schedule is None and use_duration and 'actual_duration' in demographics:
            duration_months = int(demographics['actual_duration'].get('median_months', 12))
            visit_names, _ = generate_visit_schedule(duration_months, n_visits=4)
        else:
            visit_names = visit_schedule if visit_schedule is not None else VISITS
    else:
        base_sbp, sbp_std = 130.0, 10.0
        base_dbp, dbp_std = 80.0, 8.0
        visit_names = visit_schedule if visit_schedule is not None else VISITS

    # Use coordination parameters if provided
    if subject_ids is not None:
        subs = subject_ids
    else:
        subs = [f"RA001-{i:03d}" for i in range(1, 2 * n_per_arm + 1)]

    if treatment_arms is None:
        # Generate default treatment arms
        treatment_arms = {}
        for i, sid in enumerate(subs):
            treatment_arms[sid] = "Active" if i < n_per_arm else "Placebo"

    rows = []
    for sid in subs:
        arm = treatment_arms[sid]  # Use coordinated treatment assignment
        # Subject-specific baseline (using AACT mean)
        subj_base_sbp = rng.normal(base_sbp, sbp_std)
        subj_base_dbp = rng.normal(base_dbp, dbp_std)

        for v in visit_names:
            sbp = rng.normal(subj_base_sbp, 6)

            # Apply treatment effect at final visit
            if v == visit_names[-1] and arm == "Active":
                sbp += target_effect

            dbp = rng.normal(subj_base_dbp, 5)
            hr = int(rng.integers(60, 101))
            temp = rng.normal(36.8, 0.3)

            rows.append([
                sid, v, arm,
                int(np.clip(round(sbp), 95, 200)),
                int(np.clip(round(dbp), 55, 130)),
                int(np.clip(hr, 50, 120)),
                float(np.clip(temp, 35.0, 40.0)),
            ])

    df = pd.DataFrame(rows, columns=[
        "SubjectID", "VisitName", "TreatmentArm", "SystolicBP",
        "DiastolicBP", "HeartRate", "Temperature"
    ])

    # Add fever rows
    k = int(rng.integers(1, 3))
    idx = rng.choice(df.index, size=k, replace=False)
    df.loc[idx, "Temperature"] = rng.uniform(38.1, 38.8, size=k)
    df.loc[idx, "HeartRate"] = np.maximum(df.loc[idx, "HeartRate"], 67)

    # Snap final visit effect
    final_visit = visit_names[-1]
    wk12 = df["VisitName"] == final_visit
    means = df.loc[wk12].groupby("TreatmentArm")["SystolicBP"].mean().to_dict()

    if "Active" in means and "Placebo" in means:
        current = means["Active"] - means["Placebo"]
        adjust = target_effect - current
        mask = wk12 & (df["TreatmentArm"] == "Active")
        df.loc[mask, "SystolicBP"] = (
            df.loc[mask, "SystolicBP"] + adjust
        ).round().astype(int).clip(95, 200)

    return df


def generate_demographics_aact(
    indication: str = "hypertension",
    phase: str = "Phase 3",
    n_subjects: int = 100,
    seed: int = 42,
    subject_ids: Optional[List[str]] = None,
    treatment_arms: Optional[Dict[str, str]] = None
) -> pd.DataFrame:
    """
    Generate demographics using AACT real-world distributions (v4.0)

    Enhancements over base demographics generator:
    - Uses real age distributions from AACT
    - Uses real gender distributions from AACT
    - Uses real baseline characteristics for stratification
    - Falls back to defaults if AACT data unavailable

    Args:
        indication: Disease indication
        phase: Trial phase
        n_subjects: Number of subjects
        seed: Random seed

    Returns:
        DataFrame with demographic data matching real trial patterns
    """
    rng = np.random.default_rng(seed)
    np.random.seed(seed)

    # Get AACT demographics and baseline characteristics
    if AACT_AVAILABLE:
        demographics_data = get_demographics(indication, phase)
        baseline_chars = get_baseline_characteristics(indication, phase, top_n=10)

        # Extract age distribution
        age_median = demographics_data.get('age', {}).get('median_years', 55.0)
        age_mean = demographics_data.get('age', {}).get('mean_years', 56.0)
        age_std = (age_mean - age_median) * 1.5  # Rough estimate from median/mean

        # Extract gender distribution
        gender_data = demographics_data.get('gender', {})
        male_pct = gender_data.get('male_percentage', 50.0) / 100.0
        female_pct = gender_data.get('female_percentage', 50.0) / 100.0

        # Normalize if needed
        total = male_pct + female_pct
        if total > 0:
            male_pct /= total
            female_pct /= total
        else:
            male_pct, female_pct = 0.5, 0.5

        # Get race distribution from baseline characteristics
        race_dist = baseline_chars.get('Race', {})
        if race_dist:
            races = list(race_dist.keys())
            race_probs = list(race_dist.values())
        else:
            races = ["White", "Black or African American", "Asian", "Other"]
            race_probs = [0.60, 0.13, 0.06, 0.21]
    else:
        # Fallback defaults
        age_median, age_std = 55.0, 12.0
        male_pct, female_pct = 0.5, 0.5
        races = ["White", "Black or African American", "Asian", "Other"]
        race_probs = [0.60, 0.13, 0.06, 0.21]

    # Use coordination parameters if provided
    if subject_ids is not None:
        subjects_to_generate = subject_ids
        n_subjects = len(subjects_to_generate)
    else:
        subjects_to_generate = [f"RA001-{i+1:03d}" for i in range(n_subjects)]

    demographics = []

    for subject_id in subjects_to_generate:
        # Age: Use AACT distribution
        age = int(np.clip(rng.normal(age_median, age_std), 18, 85))

        # Gender: Use AACT distribution
        gender = rng.choice(["Male", "Female"], p=[male_pct, female_pct])

        # Race: Use AACT/baseline distribution
        race = rng.choice(races, p=race_probs)

        # Ethnicity: Standard US demographics
        ethnicity = rng.choice(
            ["Hispanic or Latino", "Not Hispanic or Latino"],
            p=[0.18, 0.82]
        )

        # Height: gender-specific
        if gender == "Male":
            height_cm = rng.normal(175, 7)
        else:
            height_cm = rng.normal(162, 6.5)
        height_cm = np.clip(height_cm, 140, 220)

        # Weight: correlated with age
        base_weight = 75 if gender == "Male" else 65
        weight_kg = base_weight + rng.normal(0, 12) + (age - age_median) * 0.2
        weight_kg = np.clip(weight_kg, 40, 200)

        # BMI
        bmi = weight_kg / ((height_cm / 100) ** 2)
        bmi = np.clip(bmi, 15, 45)

        # Smoking: Age-correlated
        if age < 40:
            smoke_probs = [0.25, 0.20, 0.55]
        elif age < 60:
            smoke_probs = [0.15, 0.45, 0.40]
        else:
            smoke_probs = [0.10, 0.55, 0.35]

        smoking = rng.choice(["Current", "Former", "Never"], p=smoke_probs)

        demographics.append({
            "SubjectID": subject_id,
            "Age": age,
            "Gender": gender,
            "Race": race,
            "Ethnicity": ethnicity,
            "Height_cm": round(height_cm, 1),
            "Weight_kg": round(weight_kg, 1),
            "BMI": round(bmi, 1),
            "SmokingStatus": smoking
        })

    return pd.DataFrame(demographics)


# ============================================================================
# AACT-Enhanced Bayesian and MICE Generators (v4.0)
# ============================================================================

def generate_vitals_bayesian_aact(
    indication: str = "hypertension",
    phase: str = "Phase 3",
    n_per_arm: int = 50,
    target_effect: float = -5.0,
    seed: int = 42,
    use_duration: bool = True,
    real_data_path: Optional[str] = None,
    subject_ids: Optional[List[str]] = None,
    visit_schedule: Optional[List[str]] = None,
    treatment_arms: Optional[Dict[str, str]] = None
) -> pd.DataFrame:
    """
    Generate vitals using Bayesian Network with AACT real-world data (v4.0)

    This combines the sophisticated dependency modeling of Bayesian networks
    with real-world baseline vitals and study parameters from AACT.

    Args:
        indication: Disease indication (e.g., 'hypertension', 'diabetes')
        phase: Trial phase ('Phase 1', 'Phase 2', 'Phase 3', 'Phase 4')
        n_per_arm: Number of subjects per treatment arm
        target_effect: Target SBP reduction in mmHg (e.g., -5.0)
        seed: Random seed for reproducibility
        use_duration: If True, use AACT actual study duration
        real_data_path: Path to real data for Bayesian network training

    Returns:
        DataFrame with columns: SubjectID, VisitName, TreatmentArm,
        SystolicBP, DiastolicBP, HeartRate, Temperature

    Note:
        - Falls back to defaults if AACT data unavailable
        - Uses realistic visit schedule based on AACT duration
        - Preserves complex variable relationships via Bayesian network
    """
    try:
        # Import Bayesian generator (may not be available)
        from bayesian_generator import generate_vitals_bayesian
    except ImportError:
        raise ImportError("Bayesian generator not available. Install: pip install pgmpy")

    # Get AACT baseline vitals and demographics
    if AACT_AVAILABLE:
        baseline_vitals = get_baseline_vitals(indication, phase)
        demographics = get_demographics(indication, phase)

        # Extract AACT parameters (will use defaults if not available)
        sbp_mean = baseline_vitals.get('systolic', {}).get('mean', 140.0)
        sbp_std = baseline_vitals.get('systolic', {}).get('std', 15.0)

        # Get study duration
        duration_months = 12  # default
        if use_duration and 'actual_duration' in demographics:
            duration_months = int(demographics['actual_duration'].get('median_months', 12))

        print(f"âœ“ Using AACT data for {indication} {phase}")
        print(f"  Baseline SBP: {sbp_mean:.1f} Â± {sbp_std:.1f} mmHg")
        print(f"  Study duration: {duration_months} months")
    else:
        duration_months = 12
        print("âš ï¸  AACT data not available, using defaults")

    # Generate using Bayesian network
    # The Bayesian network will learn structure from real data
    # and generate new synthetic data with similar relationships
    df = generate_vitals_bayesian(
        n_per_arm=n_per_arm,
        target_effect=target_effect,
        seed=seed,
        real_data_path=real_data_path
    )

    # Post-process: Update visit schedule based on AACT duration or coordination
    if visit_schedule is not None:
        # Use provided visit schedule for coordination
        visit_names_to_use = visit_schedule
    elif use_duration and duration_months != 12:
        visit_names_to_use, visit_days = generate_visit_schedule(duration_months, n_visits=4)
    else:
        visit_names_to_use = None

    if visit_names_to_use is not None:
        # Map old visit names to new ones
        visit_mapping = {
            'Screening': visit_names_to_use[0],
            'Day 1': visit_names_to_use[1],
            'Week 4': visit_names_to_use[2] if len(visit_names_to_use) > 2 else 'Week 4',
            'Week 12': visit_names_to_use[3] if len(visit_names_to_use) > 3 else 'Week 12'
        }

        df['VisitName'] = df['VisitName'].map(visit_mapping)

    # Post-process: Apply coordination parameters if provided
    if subject_ids is not None or treatment_arms is not None:
        unique_subjects = df['SubjectID'].unique()

        if subject_ids is not None:
            # Map old subject IDs to coordinated ones
            subject_mapping = {}
            for i, old_subj in enumerate(unique_subjects):
                if i < len(subject_ids):
                    subject_mapping[old_subj] = subject_ids[i]
            df['SubjectID'] = df['SubjectID'].map(subject_mapping)

        if treatment_arms is not None:
            # Update treatment arms to match coordination
            for new_subj in df['SubjectID'].unique():
                if new_subj in treatment_arms:
                    df.loc[df['SubjectID'] == new_subj, 'TreatmentArm'] = treatment_arms[new_subj]

    return df


def generate_vitals_mice_aact(
    indication: str = "hypertension",
    phase: str = "Phase 3",
    n_per_arm: int = 50,
    target_effect: float = -5.0,
    seed: int = 42,
    subject_ids: Optional[List[str]] = None,
    visit_schedule: Optional[List[str]] = None,
    treatment_arms: Optional[Dict[str, str]] = None,
    use_duration: bool = True,
    missing_rate: float = 0.10,
    estimator: str = 'bayesian_ridge',
    real_data_path: Optional[str] = None
) -> pd.DataFrame:
    """
    Generate vitals using MICE with AACT real-world data (v4.0)

    This combines the missing data handling capabilities of MICE (Multiple
    Imputation by Chained Equations) with real-world baseline vitals and
    study parameters from AACT.

    Args:
        indication: Disease indication (e.g., 'hypertension', 'diabetes')
        phase: Trial phase ('Phase 1', 'Phase 2', 'Phase 3', 'Phase 4')
        n_per_arm: Number of subjects per treatment arm
        target_effect: Target SBP reduction in mmHg (e.g., -5.0)
        seed: Random seed for reproducibility
        use_duration: If True, use AACT actual study duration
        missing_rate: Fraction of values to mark as missing (0.0-0.3)
        estimator: 'bayesian_ridge' (fast) or 'random_forest' (slower, non-linear)
        real_data_path: Path to real data for MICE training

    Returns:
        DataFrame with columns: SubjectID, VisitName, TreatmentArm,
        SystolicBP, DiastolicBP, HeartRate, Temperature

    Note:
        - Falls back to defaults if AACT data unavailable
        - Uses realistic visit schedule based on AACT duration
        - Simulates and imputes missing data for realism
    """
    try:
        # Import MICE generator (may not be available)
        from mice_generator import generate_vitals_mice
    except ImportError:
        raise ImportError("MICE generator not available. Install: pip install scikit-learn")

    # Get AACT baseline vitals and demographics
    if AACT_AVAILABLE:
        baseline_vitals = get_baseline_vitals(indication, phase)
        demographics = get_demographics(indication, phase)

        # Extract AACT parameters
        sbp_mean = baseline_vitals.get('systolic', {}).get('mean', 140.0)
        sbp_std = baseline_vitals.get('systolic', {}).get('std', 15.0)

        # Get study duration
        duration_months = 12  # default
        if use_duration and 'actual_duration' in demographics:
            duration_months = int(demographics['actual_duration'].get('median_months', 12))

        print(f"âœ“ Using AACT data for {indication} {phase}")
        print(f"  Baseline SBP: {sbp_mean:.1f} Â± {sbp_std:.1f} mmHg")
        print(f"  Study duration: {duration_months} months")
        print(f"  Missing rate: {missing_rate:.1%}")
    else:
        duration_months = 12
        print("âš ï¸  AACT data not available, using defaults")

    # Generate using MICE
    df = generate_vitals_mice(
        n_per_arm=n_per_arm,
        target_effect=target_effect,
        seed=seed,
        missing_rate=missing_rate,
        estimator=estimator,
        real_data_path=real_data_path
    )

    # Post-process: Update visit schedule based on AACT duration or coordination
    if visit_schedule is not None:
        # Use provided visit schedule for coordination
        visit_names_to_use = visit_schedule
    elif use_duration and duration_months != 12:
        visit_names_to_use, visit_days = generate_visit_schedule(duration_months, n_visits=4)
    else:
        visit_names_to_use = None

    if visit_names_to_use is not None:
        # Map old visit names to new ones
        visit_mapping = {
            'Screening': visit_names_to_use[0],
            'Day 1': visit_names_to_use[1],
            'Week 4': visit_names_to_use[2] if len(visit_names_to_use) > 2 else 'Week 4',
            'Week 12': visit_names_to_use[3] if len(visit_names_to_use) > 3 else 'Week 12'
        }

        df['VisitName'] = df['VisitName'].map(visit_mapping)

    # Post-process: Apply coordination parameters if provided
    if subject_ids is not None or treatment_arms is not None:
        unique_subjects = df['SubjectID'].unique()

        if subject_ids is not None:
            # Map old subject IDs to coordinated ones
            subject_mapping = {}
            for i, old_subj in enumerate(unique_subjects):
                if i < len(subject_ids):
                    subject_mapping[old_subj] = subject_ids[i]
            df['SubjectID'] = df['SubjectID'].map(subject_mapping)

        if treatment_arms is not None:
            # Update treatment arms to match coordination
            for new_subj in df['SubjectID'].unique():
                if new_subj in treatment_arms:
                    df.loc[df['SubjectID'] == new_subj, 'TreatmentArm'] = treatment_arms[new_subj]

    return df


# ============================================================================
# AACT-Enhanced Labs and Adverse Events Generators (v4.0)
# ============================================================================

def generate_labs_aact(
    indication: str = "hypertension",
    phase: str = "Phase 3",
    n_subjects: int = 100,
    seed: int = 42,
    use_duration: bool = True,
    subject_ids: Optional[List[str]] = None,
    visit_schedule: Optional[List[str]] = None,
    treatment_arms: Optional[Dict[str, str]] = None
) -> pd.DataFrame:
    """
    Generate lab results with AACT real-world data (v4.0)

    Enhances basic lab generation with:
    - Real study duration for visit scheduling
    - Indication-specific lab abnormalities
    - Dynamic visit names based on AACT duration

    Args:
        indication: Disease indication (e.g., 'hypertension', 'diabetes')
        phase: Trial phase ('Phase 1', 'Phase 2', 'Phase 3', 'Phase 4')
        n_subjects: Number of subjects
        seed: Random seed for reproducibility
        use_duration: If True, use AACT actual study duration

    Returns:
        DataFrame with lab results including hematology, chemistry, and lipids
        for multiple visits per subject
    """
    np.random.seed(seed)
    rng = np.random.default_rng(seed)

    # Get AACT duration if available
    duration_months = 12  # default
    if AACT_AVAILABLE and use_duration:
        demographics = get_demographics(indication, phase)
        if 'actual_duration' in demographics:
            duration_months = int(demographics['actual_duration'].get('median_months', 12))
            print(f"âœ“ Using AACT duration: {duration_months} months for {indication} {phase}")
    else:
        if use_duration:
            print("âš ï¸  AACT data not available, using default duration: 12 months")

    # Use provided visit schedule or generate from AACT/defaults
    if visit_schedule is not None:
        visit_names = visit_schedule
    elif use_duration and duration_months != 12:
        visit_names, _ = generate_visit_schedule(duration_months, n_visits=3)
    else:
        visit_names = ["Screening", "Week 4", "Week 12"]

    # Use provided subject IDs or generate defaults
    if subject_ids is not None:
        subjects_to_generate = subject_ids
        n_subjects = len(subjects_to_generate)
    else:
        subjects_to_generate = [f"RA001-{i+1:03d}" for i in range(n_subjects)]

    labs = []

    for subject_id in subjects_to_generate:
        for visit in visit_names:
            # Hematology (Complete Blood Count)
            hemoglobin = rng.normal(14.5, 1.5)  # 12-18 g/dL
            hemoglobin = np.clip(hemoglobin, 12, 18)

            hematocrit = hemoglobin * 3  # Hct â‰ˆ 3Ã— Hgb
            hematocrit = np.clip(hematocrit, 36, 50)

            wbc = rng.normal(7.5, 1.5)  # 4-11 K/Î¼L
            wbc = np.clip(wbc, 4, 11)

            platelets = rng.normal(250, 50)  # 150-400 K/Î¼L
            platelets = np.clip(platelets, 150, 400)

            # Chemistry (Metabolic Panel)
            glucose = rng.normal(90, 10)  # 70-100 mg/dL
            glucose = np.clip(glucose, 70, 120)

            # Indication-specific adjustments
            if indication.lower() == "diabetes":
                # Diabetics have higher glucose
                glucose = rng.normal(140, 20)
                glucose = np.clip(glucose, 100, 200)

            creatinine = rng.normal(1.0, 0.15)  # 0.7-1.3 mg/dL
            creatinine = np.clip(creatinine, 0.7, 1.3)

            bun = rng.normal(15, 3)  # 7-20 mg/dL
            bun = np.clip(bun, 7, 20)

            alt = rng.normal(30, 10)  # 7-56 U/L
            alt = np.clip(alt, 7, 56)

            ast = rng.normal(25, 8)  # 10-40 U/L
            ast = np.clip(ast, 10, 40)

            bilirubin = rng.normal(0.7, 0.2)  # 0.3-1.2 mg/dL
            bilirubin = np.clip(bilirubin, 0.3, 1.2)

            # Lipids
            total_chol = rng.normal(190, 30)
            total_chol = np.clip(total_chol, 120, 300)

            ldl = rng.normal(110, 25)
            ldl = np.clip(ldl, 50, 200)

            hdl = rng.normal(50, 10)
            hdl = np.clip(hdl, 30, 80)

            triglycerides = rng.normal(150, 40)
            triglycerides = np.clip(triglycerides, 50, 250)

            labs.append({
                "SubjectID": subject_id,
                "VisitName": visit,
                "Hemoglobin": round(hemoglobin, 1),
                "Hematocrit": round(hematocrit, 1),
                "WBC": round(wbc, 1),
                "Platelets": round(platelets, 0),
                "Glucose": round(glucose, 0),
                "Creatinine": round(creatinine, 2),
                "BUN": round(bun, 1),
                "ALT": round(alt, 0),
                "AST": round(ast, 0),
                "Bilirubin": round(bilirubin, 2),
                "TotalCholesterol": round(total_chol, 0),
                "LDL": round(ldl, 0),
                "HDL": round(hdl, 0),
                "Triglycerides": round(triglycerides, 0)
            })

    return pd.DataFrame(labs)


def generate_oncology_ae_aact(
    indication: str = "cancer",
    phase: str = "Phase 2",
    n_subjects: int = 30,
    seed: int = 7,
    subject_ids: Optional[List[str]] = None,
    visit_schedule: Optional[List[str]] = None,
    treatment_arms: Optional[Dict[str, str]] = None
) -> pd.DataFrame:
    """
    Generate adverse events with AACT real-world data (v4.0)

    Enhances basic AE generation with:
    - Indication-specific AE terms
    - Phase-specific severity distributions
    - Real-world AE rates from AACT

    Args:
        indication: Disease indication (e.g., 'cancer', 'hypertension', 'diabetes')
        phase: Trial phase ('Phase 1', 'Phase 2', 'Phase 3', 'Phase 4')
        n_subjects: Number of subjects
        seed: Random seed for reproducibility
        subject_ids: Optional list of subject IDs to use (for comprehensive study)
                    If None, generates "ONC001", "ONC002", etc.

    Returns:
        DataFrame with SDTM AE domain structure
    """
    rng = np.random.default_rng(seed)

    # Use provided subject IDs or generate default ones
    if subject_ids is not None:
        subjects = subject_ids
        n_subjects = len(subjects)
    else:
        subjects = [f"ONC{idx:03d}" for idx in range(1, n_subjects + 1)]

    # Indication-specific AE terms
    if indication.lower() in ["cancer", "oncology"]:
        terms = [
            ("Neutropenia", "Blood and lymphatic system disorders"),
            ("Nausea", "Gastrointestinal disorders"),
            ("Anemia", "Blood and lymphatic system disorders"),
            ("Fatigue", "General disorders and administration site conditions"),
            ("Elevated ALT", "Hepatobiliary disorders"),
            ("Myelosuppression", "Blood and lymphatic system disorders"),
            ("Peripheral neuropathy", "Nervous system disorders"),
        ]
    elif indication.lower() == "hypertension":
        terms = [
            ("Dizziness", "Nervous system disorders"),
            ("Headache", "Nervous system disorders"),
            ("Hypotension", "Vascular disorders"),
            ("Fatigue", "General disorders and administration site conditions"),
            ("Peripheral edema", "General disorders and administration site conditions"),
        ]
    elif indication.lower() == "diabetes":
        terms = [
            ("Hypoglycemia", "Metabolism and nutrition disorders"),
            ("Weight gain", "Metabolism and nutrition disorders"),
            ("Nausea", "Gastrointestinal disorders"),
            ("Diarrhea", "Gastrointestinal disorders"),
            ("Headache", "Nervous system disorders"),
        ]
    else:
        # Generic terms
        terms = [
            ("Headache", "Nervous system disorders"),
            ("Nausea", "Gastrointestinal disorders"),
            ("Fatigue", "General disorders and administration site conditions"),
            ("Dizziness", "Nervous system disorders"),
            ("Rash", "Skin and subcutaneous tissue disorders"),
        ]

    rows = []

    # Phase-specific severity - early phase trials have more serious AEs
    serious_rate = 0.3 if phase in ["Phase 1", "Phase 2"] else 0.15

    # Guarantee at least 1 serious+related AE
    if indication.lower() in ["cancer", "oncology"]:
        rows.append([
            rng.choice(subjects),
            "Myelosuppression",
            "Blood and lymphatic system disorders",
            "Y",  # Serious
            "Y",  # Related
            "ONGOING"
        ])

    # Generate AEs for subjects
    n_aes = max(20, int(n_subjects * 0.7))  # ~70% of subjects have at least one AE

    for _ in range(n_aes):
        subj = rng.choice(subjects)
        term, bodsys = terms[rng.integers(0, len(terms))]

        # Serious AE based on phase
        ser = "Y" if rng.random() < serious_rate else "N"

        # Related to study drug
        rel = "Y" if rng.random() < 0.6 else "N"

        # Outcome
        if ser == "Y" and rng.random() < 0.05:  # 5% of serious AEs are fatal
            out = "FATAL"
        elif rng.random() < 0.8:
            out = "RESOLVED"
        else:
            out = "ONGOING"

        rows.append([subj, term, bodsys, ser, rel, out])

    df = pd.DataFrame(rows, columns=["USUBJID", "AETERM", "AEBODSYS", "AESER", "AEREL", "AEOUT"])

    # Rename columns to match frontend expectations (non-SDTM names for UI display)
    df = df.rename(columns={
        "USUBJID": "SubjectID",
        "AETERM": "AETerm",
        "AEBODSYS": "BodySystem",
        "AESER": "Serious",
        "AEREL": "Related",
        "AEOUT": "Outcome"
    })

    if AACT_AVAILABLE:
        print(f"âœ“ Generated {len(df)} AEs for {indication} {phase} using AACT patterns")
    else:
        print(f"âœ“ Generated {len(df)} AEs (using fallback defaults)")

    return df
